{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siamnet import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = '../data_omniglot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path,\"train.pickle\"), \"rb\") as file:\n",
    "    imgs_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path,\"val.pickle\"), \"rb\") as file:\n",
    "    imgs_validate = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1 = tf.placeholder(tf.float32, shape=[None, 105, 105, 1])\n",
    "img2 = tf.placeholder(tf.float32, shape=[None, 105, 105, 1])\n",
    "diffclass = tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 1\n",
    "\n",
    "features1 = api.convnet(img1, reuse=False)\n",
    "features2 = api.convnet(img2, reuse=True)\n",
    "\n",
    "diff = tf.sqrt(tf.reduce_mean(tf.square(features1 - features2),axis=1))\n",
    "diff = tf.reshape(diff,[-1,1])\n",
    "\n",
    "loss = tf.reduce_mean((1-diffclass)*diff**2 / 2 + diffclass*(tf.maximum(0.,m-diff))**2/2)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(\n",
    "        learning_rate = 0.0001)\n",
    "train_op = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "trainsteps = 5\n",
    "printstep = 500\n",
    "l = np.zeros(trainsteps)\n",
    "acc = np.zeros(trainsteps)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(trainsteps):\n",
    "        batch, batch_diff = api.getbatch(imgs_train, batchsize)\n",
    "        _,l[step] = sess.run([train_op,loss], feed_dict={img1: batch[0,:,:,:,:],\n",
    "                                               img2: batch[1,:,:,:,:],\n",
    "                                               diffclass: batch_diff})\n",
    "        if ((step+1)%printstep==0):\n",
    "            print('Step %d: Loss %f, Accuracy %f' % (step,np.mean(l[step-printstep+1:step+1]),\n",
    "                                                     np.mean(acc[step-printstep+1:step+1])))\n",
    "            \n",
    "    saver.save(sess, './checkpoints/model', step)\n",
    "#         print(np.matrix([p[:,0],batch_diff[:,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare image 0 to images 15-19 and find closest match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_compare = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_img = 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs_validate[find_img,0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    diff_val=np.zeros([imgs_validate.shape[0],num_compare])\n",
    "    for i in range(imgs_validate.shape[0]):\n",
    "        for j in range(20-num_compare,20):\n",
    "            diff_val[i][j-20+num_compare] = sess.run(diff, feed_dict={\n",
    "                img1: np.reshape(imgs_validate[find_img,0,:,:],[1,105,105,1]),\n",
    "                img2: np.reshape(imgs_validate[i,j,:,:],[1,105,105,1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_match = np.argmin(np.mean(diff_val,1))\n",
    "print(closest_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_val[find_img])\n",
    "print(diff_val[closest_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,num_compare,figsize=(20,10))\n",
    "ax[0,0].imshow(imgs_validate[find_img,0,:,:])\n",
    "for i in range(20-num_compare,20):\n",
    "    ax[1,i-20+num_compare].imshow(imgs_validate[find_img,i,:,:])\n",
    "    ax[2,i-20+num_compare].imshow(imgs_validate[closest_match,i,:,:])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

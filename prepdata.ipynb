{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Script to preprocess the omniglot dataset and pickle it into an array that's easy\\n    to index my character type\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\"\"\"Script to preprocess the omniglot dataset and pickle it into an array that's easy\n",
    "    to index my character type\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/djustus/workspace/omniglot/'\n",
    "data_path = os.path.join(path ,\"python\")\n",
    "train_folder = os.path.join(data_path,'images_background')\n",
    "valpath = os.path.join(data_path,'images_evaluation')\n",
    "\n",
    "save_path = '/Users/djustus/workspace/siamese/'\n",
    "\n",
    "lang_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadimgs(path,n=0):\n",
    "    #if data not already unzipped, unzip it.\n",
    "    if not os.path.exists(path):\n",
    "        print(\"unzipping\")\n",
    "        os.chdir(data_path)\n",
    "        os.system(\"unzip {}\".format(path+\".zip\" ))\n",
    "    imgs = []\n",
    "    #we load every alphabet seperately so we can isolate them later\n",
    "    for alphabet in os.listdir(path):\n",
    "        if not alphabet[0] =='.':\n",
    "            print(\"loading alphabet: \" + alphabet)\n",
    "            alphabet_path = os.path.join(path,alphabet)\n",
    "            #every letter/category has it's own column in the array, so  load seperately\n",
    "            for letter in os.listdir(alphabet_path):\n",
    "                category_images=[]\n",
    "                letter_path = os.path.join(alphabet_path, letter)\n",
    "                for filename in os.listdir(letter_path):\n",
    "                    image_path = os.path.join(letter_path, filename)\n",
    "                    image = imread(image_path)\n",
    "                    category_images.append(image)\n",
    "                try:\n",
    "                    imgs.append(np.stack(category_images))\n",
    "                #edge case  - last one\n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images:\", category_images)\n",
    "    imgs = np.stack(imgs)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading alphabet: Gujarati\n",
      "loading alphabet: Korean\n",
      "loading alphabet: Arcadian\n",
      "loading alphabet: Malay_(Jawi_-_Arabic)\n",
      "loading alphabet: Grantha\n",
      "loading alphabet: Blackfoot_(Canadian_Aboriginal_Syllabics)\n",
      "loading alphabet: Balinese\n",
      "loading alphabet: Futurama\n",
      "loading alphabet: N_Ko\n",
      "loading alphabet: Burmese_(Myanmar)\n",
      "loading alphabet: Anglo-Saxon_Futhorc\n",
      "loading alphabet: Mkhedruli_(Georgian)\n",
      "loading alphabet: Latin\n",
      "loading alphabet: Braille\n",
      "loading alphabet: Sanskrit\n",
      "loading alphabet: Japanese_(hiragana)\n",
      "loading alphabet: Tagalog\n",
      "loading alphabet: Greek\n",
      "loading alphabet: Ojibwe_(Canadian_Aboriginal_Syllabics)\n",
      "loading alphabet: Japanese_(katakana)\n",
      "loading alphabet: Early_Aramaic\n",
      "loading alphabet: Hebrew\n",
      "loading alphabet: Tifinagh\n",
      "loading alphabet: Asomtavruli_(Georgian)\n",
      "loading alphabet: Armenian\n",
      "loading alphabet: Syriac_(Estrangelo)\n",
      "loading alphabet: Alphabet_of_the_Magi\n",
      "loading alphabet: Cyrillic\n",
      "loading alphabet: Bengali\n",
      "loading alphabet: Inuktitut_(Canadian_Aboriginal_Syllabics)\n"
     ]
    }
   ],
   "source": [
    "imgs_train = loadimgs(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(964, 20, 105, 105)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path,\"train.pickle\"), \"wb\") as file:\n",
    "    pickle.dump(imgs_train,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading alphabet: Oriya\n",
      "loading alphabet: ULOG\n",
      "loading alphabet: Tengwar\n",
      "loading alphabet: Malayalam\n",
      "loading alphabet: Atlantean\n",
      "loading alphabet: Keble\n",
      "loading alphabet: Manipuri\n",
      "loading alphabet: Gurmukhi\n",
      "loading alphabet: Tibetan\n",
      "loading alphabet: Aurek-Besh\n",
      "loading alphabet: Ge_ez\n",
      "loading alphabet: Angelic\n",
      "loading alphabet: Old_Church_Slavonic_(Cyrillic)\n",
      "loading alphabet: Kannada\n",
      "loading alphabet: Avesta\n",
      "loading alphabet: Mongolian\n",
      "loading alphabet: Syriac_(Serto)\n",
      "loading alphabet: Atemayar_Qelisayer\n",
      "loading alphabet: Sylheti\n",
      "loading alphabet: Glagolitic\n"
     ]
    }
   ],
   "source": [
    "imgs_val = loadimgs(valpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path,\"val.pickle\"), \"wb\") as file:\n",
    "    pickle.dump(imgs_val,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 105, 105)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([imgs_train[1][1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
